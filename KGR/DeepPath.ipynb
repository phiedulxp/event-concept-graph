{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'BFS',\n",
       " 'DeepPath.ipynb',\n",
       " 'env.py',\n",
       " 'evaluate.py',\n",
       " 'fact_prediction_eval.py',\n",
       " 'link_prediction_eval.sh',\n",
       " 'networks.py',\n",
       " 'pathfinder.sh',\n",
       " 'policy_agent.py',\n",
       " 'sl_policy.py',\n",
       " 'transE_eval.py',\n",
       " 'transR_eval.py',\n",
       " 'transX_eval.py',\n",
       " 'utils.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BFS.py',\n",
       " 'BFS.pyc',\n",
       " 'DFS.pyc',\n",
       " 'full_data.txt',\n",
       " 'KB.py',\n",
       " 'KB.pyc',\n",
       " 'README',\n",
       " 'run.py',\n",
       " '__init__.py',\n",
       " '__init__.pyc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./BFS/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fact_prediction_eval.py\n",
    "```\n",
    "def bfs_two\n",
    "def get_features\n",
    "ap:\n",
    "TransE\n",
    "TransR\n",
    "RL\n",
    "TransH\n",
    "TransD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relation = 'concept_worksfor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_path = '../../NELL-995/tasks/' + relation +'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict\n",
    "entity2id = dict([(line.split()[0],int(line.split()[1])) for line in \\\n",
    "                  codecs.open(task_path+'entity2id.txt','r',encoding='utf-8') if len(line.split()) == 2])\n",
    "relation2id = dict([(line.split()[0],int(line.split()[1])) for line in \\\n",
    "                    codecs.open(task_path+'relation2id.txt','r',encoding='utf-8') if len(line.split()) == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75492"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relation2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rel\n",
    "rel = relation.replace(\"_\", \":\") # concept_athletehomestadium -> concept:athletehomestadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TransE\n",
    "ent_vec_E = np.loadtxt(task_path+'entity2vec.unif')\n",
    "rel_vec_E = np.loadtxt(task_path+'relation2vec.unif')\n",
    "relation_vec_E = rel_vec_E[relation2id[rel],:] # TransE relation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation2id[rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75492, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_vec_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_vec_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_vec_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TransR\n",
    "ent_vec_R = np.loadtxt(task_path+'entity2vec.bern')\n",
    "rel_vec_R = np.loadtxt(task_path+'relation2vec.bern')\n",
    "M_R = np.loadtxt(task_path+'A.bern') #投影矩阵\n",
    "M_R = M_R.reshape([-1,50,50])\n",
    "relation_vec_R = rel_vec_R[relation2id[rel],:]#关系向量TransR\n",
    "M_R_vec = M_R[relation2id[rel],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(task_path+'A.bern').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 50, 50)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_R_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TransH\n",
    "ent_vec_H = np.loadtxt(task_path+'entity2vec.vec')\n",
    "rel_vec_H = np.loadtxt(task_path+'relation2vec.vec')\n",
    "M_H = np.loadtxt(task_path+'A.vec')\n",
    "M_H = M_H.reshape([rel_vec_H.shape[0],-1])\n",
    "relation_vec_H = d_r = np.expand_dims(rel_vec_H[relation2id[rel],:],1)\n",
    "w_r = np.expand_dims(M_H[relation2id[rel],:],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 50)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TransD\n",
    "ent_vec_D = np.loadtxt(task_path+'entity2vec.vec_D')\n",
    "rel_vec_D = np.loadtxt(task_path+'relation2vec.vec_D')\n",
    "M_D = np.loadtxt(task_path+'A.vec_D')\n",
    "ent_num = ent_vec_D.shape[0]\n",
    "rel_num = rel_vec_D.shape[0]\n",
    "rel_tran = M_D[0:rel_num,:]\n",
    "ent_tran = M_D[rel_num:,:]\n",
    "dim_D = ent_vec_D.shape[1]\n",
    "\n",
    "r = np.expand_dims(rel_vec_D[relation2id[rel],:], 1)\n",
    "r_p = np.expand_dims(rel_tran[relation2id[rel],:], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(task_path,relation2id):\n",
    "    stats = dict([(line.split('\\t')[0],int(line.split('\\t')[1])) for line in \\\n",
    "                  codecs.open(task_path+'path_stats.txt','r',encoding='utf-8') if len(line.split()) == 2])\n",
    "    max_freq = max(stats.values()) #路径最大次数\n",
    "    useful_paths = [] # ids path list\n",
    "    named_paths = [] # rel_names path list\n",
    "    paths = [line.rstrip() for line in codecs.open(task_path+'path_to_use.txt','r',encoding='utf-8')]\n",
    "    for path in paths:\n",
    "        # filter: not in stats and count less\n",
    "        if path not in stats:\n",
    "            continue\n",
    "        elif max_freq > 1 and stats[path] < 2: \n",
    "            continue\n",
    "        # filter: len(path)<=0\n",
    "        if len(path.split(' -> ')) <= 10:\n",
    "            pathIndex = []\n",
    "            pathName = []\n",
    "            relations = path.split(' -> ')\n",
    "            for rel in relations:\n",
    "                pathName.append(rel)\n",
    "                rel_id = relation2id[rel]\n",
    "                pathIndex.append(rel_id)\n",
    "            useful_paths.append(pathIndex)\n",
    "            named_paths.append(pathName)\n",
    "    return useful_paths, named_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features\n",
    "id_path,name_path = get_features(task_path,relation2id)\n",
    "path_weights = np.array([1.0/len(path) for path in name_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[130], [254], [15], [193], [252], [35]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['concept:personleadsorganization'],\n",
       " ['concept:organizationhiredperson_inv'],\n",
       " ['concept:agentcollaborateswithagent_inv'],\n",
       " ['concept:journalistwritesforpublication'],\n",
       " ['concept:mutualproxyfor_inv'],\n",
       " ['concept:organizationterminatedperson_inv']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KB(object):\n",
    "    def __init__(self):\n",
    "        self.entities = {} # {'实体id':[Path.{relation,entity2},]}\n",
    "\n",
    "    def addRelation(self, entity1, relation, entity2):\n",
    "        # add direct connections\n",
    "        if entity1 in self.entities.keys():\n",
    "            self.entities[entity1].append(Path(relation, entity2))\n",
    "        else:\n",
    "            self.entities[entity1] = [Path(relation, entity2)] # entities{entity1：Path{.relation.connected_entity}(relation, entity2)}\n",
    "\n",
    "    def getPathsFrom(self, entity):\n",
    "        return self.entities[entity]\n",
    "\n",
    "    def removePath(self, entity1, entity2):\n",
    "        # remove direct connection between e1 and e2\n",
    "        for idx, path in enumerate(self.entities[entity1]):\n",
    "            if(path.connected_entity == entity2):\n",
    "                del self.entities[entity1][idx]\n",
    "                break\n",
    "        for idx, path in enumerate(self.entities[entity2]):\n",
    "            if(path.connected_entity == entity1):\n",
    "                del self.entities[entity2][idx]\n",
    "                break\n",
    "\n",
    "    def pickRandomIntermediatesBetween(self, entity1, entity2, num):\n",
    "        #TO DO: COULD BE IMPROVED BY NARROWING THE RANGE OF RANDOM EACH TIME ITERATIVELY CHOOSE AN INTERMEDIATE  \n",
    "        from sets import Set\n",
    "        import random\n",
    "\n",
    "        res = Set()\n",
    "        if num > len(self.entities) - 2:\n",
    "            raise ValueError('Number of Intermediates picked is larger than possible', 'num_entities: {}'.format(len(self.entities)), 'num_itermediates: {}'.format(num))\n",
    "        for i in range(num):\n",
    "            itermediate = random.choice(self.entities.keys())\n",
    "            while itermediate in res or itermediate == entity1 or itermediate == entity2:\n",
    "                itermediate = random.choice(self.entities.keys())\n",
    "            res.add(itermediate)\n",
    "        return list(res)\n",
    "\n",
    "    def __str__(self):\n",
    "        string = \"\"\n",
    "        for entity in self.entities:\n",
    "            string += entity + ','.join(str(x) for x in self.entities[entity])\n",
    "            string += '\\n'\n",
    "        return string\n",
    "\n",
    "\n",
    "class Path(object):\n",
    "    def __init__(self, relation, connected_entity):\n",
    "        self.relation = relation\n",
    "        self.connected_entity = connected_entity\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\t{}\\t{}\".format(self.relation, self.connected_entity)\n",
    "\n",
    "    __repr__ = __str__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kb\n",
    "kb = KB()       #知识库\n",
    "kb_inv = KB()   #逆向\n",
    "for line in codecs.open(task_path+'graph.txt'):\n",
    "    e1,rel,e2 = line.split()\n",
    "    kb.addRelation(e1,rel,e2)     # entities{entity1：Path{.relation.connected_entity}(relation, entity2)}\n",
    "    kb_inv.addRelation(e2,rel,e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75227"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kb.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75227"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kb_inv.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\tconcept:proxyfor\tconcept_book_new,\n",
       " \tconcept:locationlocatedwithinlocation_inv\tconcept_lake_new,\n",
       " \tconcept:atlocation_inv\tconcept_beverage_new]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.entities['concept_politicsblog_perspective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\tconcept:proxyfor_inv\tconcept_book_new,\n",
       " \tconcept:locationlocatedwithinlocation\tconcept_lake_new,\n",
       " \tconcept:atlocation\tconcept_beverage_new]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_inv.entities['concept_politicsblog_perspective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read_samples\n",
    "# thing$concept_politician_sam_sullivan,thing$concept_city_whistler:-\n",
    "def read_samples(task_path,pairs_file='train.pairs'):\n",
    "    pairs,labels = [],[]\n",
    "    for line in codecs.open(task_path+pairs_file,'r',encoding='utf-8'):\n",
    "        e1 = line.split(',')[0].replace('thing$','')\n",
    "        e2 = line.split(',')[1].split(':')[0].replace('thing$','')\n",
    "        if (e1 not in kb.entities) or (e2 not in kb.entities):\n",
    "            continue\n",
    "        pairs.append((e1,e2))\n",
    "        labels.append(1 if line[-2] == '+' else 0)\n",
    "    return pairs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs,test_labels = read_samples(task_path,'sort_test.pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('concept_actor_peter_king', 'concept_blog_sports_illustrated'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_company_post'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_company_sun'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_company_sun_microsystems001'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_newspaper_journal')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2698"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set().add('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bi_path_search(e1,e2,path,kb,kb_inv):\n",
    "    '''\n",
    "    :the bidirectional search for reasoning\n",
    "    e1,r1,ex,r2,e2\n",
    "    path:start-><-end:r1,r2\n",
    "    kb:->:e1,r1,ex|ex,r2,e2\n",
    "    kb_inv:<-:ex,r1,e1|e2,r2,ex\n",
    "    '''\n",
    "    start,end = 0,len(path)\n",
    "    left,right = set(),set()\n",
    "    left.add(e1)\n",
    "    right.add(e2)\n",
    "    left_path,right_path = [],[]\n",
    "    while(start < end):\n",
    "        left_step = path[start]\n",
    "        left_next = set()\n",
    "        right_step = path[end-1]\n",
    "        right_next = set()\n",
    "\n",
    "        if len(left) < len(right):\n",
    "            left_path.append(left_step)\n",
    "            start += 1\n",
    "            for entity in left: # BFS loop\n",
    "                try:\n",
    "                    for path_ in kb.getPathsFrom(entity):\n",
    "                        if path_.relation == left_step:\n",
    "                            left_next.add(path_.connected_entity)\n",
    "                except Exception as e:\n",
    "                    #print('len(left):',len(left),left,'not such entity')\n",
    "                    return False\n",
    "            left = left_next\n",
    "\n",
    "        else: # start->end;kb->kb_inv\n",
    "            right_path.append(right_step)\n",
    "            end -= 1\n",
    "            for entity in right:\n",
    "                try:\n",
    "                    for path_ in kb_inv.getPathsFrom(entity):\n",
    "                        if path_.relation == right_step:\n",
    "                            right_next.add(path_.connected_entity)\n",
    "                except Exception as e:\n",
    "                    #print('len(right):',len(right),right,'not such entity')\n",
    "                    return False\n",
    "            right = right_next\n",
    "    #if len(right & left) != 0:\n",
    "     #   print(left,right)\n",
    "    return True if len(right & left) != 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aps\n",
    "def entity2vec(ent_vec,entity,M_vec=None,w_r=None):\n",
    "    if isinstance(w_r,np.ndarray):\n",
    "        ent = np.expand_dims(ent_vec[entity2id[entity],:],1)\n",
    "        ent_ = ent - np.matmul(w_r.transpose(), ent)*w_r\n",
    "        return ent_\n",
    "    if isinstance(M_vec,np.ndarray):\n",
    "        return np.matmul(ent_vec[entity2id[entity],:], M_vec)\n",
    "    return ent_vec[entity2id[entity],:]\n",
    "\n",
    "def l2_score(h,r,t):\n",
    "    return -np.sum(np.square(h + r - t))\n",
    "\n",
    "scores_E = [l2_score(entity2vec(ent_vec_E,pair[0]),relation_vec_E,entity2vec(ent_vec_E,pair[1])) for pair in test_pairs]\n",
    "scores_R = [l2_score(entity2vec(ent_vec_R,pair[0],M_vec=M_R_vec),relation_vec_R,entity2vec(ent_vec_R,pair[1],M_vec=M_R_vec)) for pair in test_pairs]\n",
    "scores_rl = [sum(path_weights*[int(bi_path_search(pair[0], pair[1], path, kb, kb_inv)) for path in name_path]) for pair in test_pairs]\n",
    "scores_H = [l2_score(entity2vec(ent_vec_H,pair[0],w_r=w_r),relation_vec_H,entity2vec(ent_vec_H,pair[1],w_r=w_r)) for pair in test_pairs]\n",
    "\n",
    "def score_D(ent_vec_D,ent_tran,pair):\n",
    "    h = np.expand_dims(ent_vec_D[entity2id[pair[0]],:], 1)\n",
    "    h_p = np.expand_dims(ent_tran[entity2id[pair[0]],:], 1)\n",
    "    t = np.expand_dims(ent_vec_D[entity2id[pair[1]],:], 1)\n",
    "    t_p = np.expand_dims(ent_tran[entity2id[pair[1]],:], 1)\n",
    "    M_rh = np.matmul(r_p, h_p.transpose()) + np.identity(dim)\n",
    "    M_rt = np.matmul(r_p, t_p.transpose()) + np.identity(dim)\n",
    "    score = - np.sum(np.square(M_rh.dot(h) + r - M_rt.dot(t)))\n",
    "    return score\n",
    "    \n",
    "scores_D =[score_D(ent_vec_D,ent_tran,pair) for pair in test_pairs] \n",
    "\n",
    "def ap(scores,test_labels):\n",
    "    # evaluate rank quality\n",
    "    # 1 1 1 0 0 0 better than 0 0 0 1 1 1\n",
    "    rank_stats = sorted(zip(scores, test_labels),key = lambda x:x[0], reverse=True)\n",
    "    correct = 0\n",
    "    ranks = []\n",
    "    for idx, item in enumerate(rank_stats):\n",
    "        if item[1] == 1:\n",
    "            correct += 1\n",
    "            ranks.append(correct/(1.0+idx)) # append precision\n",
    "    return np.mean(ranks) if len(ranks) != 0 else 0\n",
    "\n",
    "models = {\n",
    "    'E':ap(scores_E, test_labels),\n",
    "    'R':ap(scores_R, test_labels),\n",
    "    'rl':ap(scores_rl, test_labels),\n",
    "    'H':ap(scores_H, test_labels),\n",
    "    'D':ap(scores_D, test_labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 0.23670935347580135,\n",
       " 'E': 0.23067132455999617,\n",
       " 'H': 0.2476364956250818,\n",
       " 'R': 0.28690542314091916,\n",
       " 'rl': 0.48808056673088396}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mAP = np.sum((recalls[indices] - recalls[indices - 1]) *\n",
    "                 precisions[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link_prediction_eval.sh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "relation=$1\n",
    "\n",
    "python evaluate.py $relation \n",
    "python transR_eval.py $relation\n",
    "python transE_eval.py $relation\n",
    "python transX_eval.py $relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(kb, kb_inv, name_path):\n",
    "    train_pairs,train_labels = read_samples(task_path,'train.pairs')\n",
    "    training_features = [[int(bi_path_search(pair[0], pair[1], path, kb, kb_inv)) for path in name_path] for pair in train_pairs]\n",
    "    model = Sequential()\n",
    "    input_dim = len(name_path)\n",
    "    model.add(Dense(1, activation='sigmoid' ,input_dim=input_dim))\n",
    "    model.compile(optimizer = 'rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(training_features, train_labels, nb_epoch=300, batch_size=128)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = train(kb, kb_inv, name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.5511950207386302\n"
     ]
    }
   ],
   "source": [
    "y_scores = [model.predict(np.reshape([int(bi_path_search(pair[0], pair[1], path, kb, kb_inv)) for path in name_path],[1,-1])) for pair in test_pairs]\n",
    "ap_link = ap(y_scores,test_labels)\n",
    "mAP = np.mean(ap_link)\n",
    "print('mAP:',mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
