{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os,sys,time,codecs,random\n",
    "from queue import Queue\n",
    "from collections import namedtuple, Counter\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'BFS',\n",
       " 'DeepPath.ipynb',\n",
       " 'env.py',\n",
       " 'evaluate.py',\n",
       " 'fact_prediction_eval.py',\n",
       " 'link_prediction_eval.sh',\n",
       " 'networks.py',\n",
       " 'pathfinder.sh',\n",
       " 'policy_agent.py',\n",
       " 'sl_policy.py',\n",
       " 'transE_eval.py',\n",
       " 'transR_eval.py',\n",
       " 'transX_eval.py',\n",
       " 'utils.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BFS.py',\n",
       " 'BFS.pyc',\n",
       " 'DFS.pyc',\n",
       " 'full_data.txt',\n",
       " 'KB.py',\n",
       " 'KB.pyc',\n",
       " 'README',\n",
       " 'run.py',\n",
       " '__init__.py',\n",
       " '__init__.pyc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./BFS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relation = 'concept_worksfor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path =  '../../NELL-995/'\n",
    "task_path = data_path + 'tasks/' + relation +'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pathfinder.sh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "relation=$1\n",
    "python sl_policy.py $relation\n",
    "python policy_agent.py $relation retrain\n",
    "python policy_agent.py $relation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KB.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KB(object):\n",
    "    def __init__(self):\n",
    "        self.entities = {} # {'实体id':[Path.{relation,entity2},]}\n",
    "\n",
    "    def addRelation(self, entity1, relation, entity2):\n",
    "        # add direct connections\n",
    "        if entity1 in self.entities.keys():\n",
    "            self.entities[entity1].append(Path(relation, entity2))\n",
    "        else:\n",
    "            # entities{entity1：Path{.relation.connected_entity}}\n",
    "            self.entities[entity1] = [Path(relation, entity2)] \n",
    "           \n",
    "\n",
    "    def getPathsFrom(self, entity):\n",
    "        return self.entities[entity]\n",
    "\n",
    "    def removePath(self, entity1, entity2):\n",
    "        # remove direct connection between e1 and e2\n",
    "        for idx, path in enumerate(self.entities[entity1]):\n",
    "            if(path.connected_entity == entity2):\n",
    "                del self.entities[entity1][idx]\n",
    "                break\n",
    "        for idx, path in enumerate(self.entities[entity2]):\n",
    "            if(path.connected_entity == entity1):\n",
    "                del self.entities[entity2][idx]\n",
    "                break\n",
    "\n",
    "    def pickRandomIntermediatesBetween(self, entity1, entity2, num):\n",
    "        # TO DO: COULD BE IMPROVED BY NARROWING THE RANGE OF\n",
    "        # RANDOM EACH TIME ITERATIVELY CHOOSE AN INTERMEDIATE  \n",
    "        if num > len(self.entities) - 2:\n",
    "            raise ValueError('Number of Intermediates picked is larger than possible',\\\n",
    "                             'num_entities: {}'.format(len(self.entities)), \\\n",
    "                             'num_itermediates: {}'.format(num))\n",
    "        return random.sample(set(self.entities.keys())-set([entity1,entity2]),num) # non-return samples\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''.join([entity+','.join([str(path) for path in self.entities[entity]]) \\\n",
    "                        for entity in self.entities])\n",
    "\n",
    "class Path(object):\n",
    "    def __init__(self, relation, connected_entity):\n",
    "        self.relation = relation\n",
    "        self.connected_entity = connected_entity\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"rel:{},next_entity:{}\".format(self.relation, self.connected_entity)\n",
    "\n",
    "    __repr__ = __str__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BFS.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class foundPaths(object):\n",
    "    def __init__(self, kb):\n",
    "        # {entity:status}\n",
    "        # status:(isFound,prevNode,relation)\n",
    "        self.entities = dict([(entity,(False,'','')) \\\n",
    "                              for entity in kb.entities.keys()])\n",
    "\n",
    "    def isFound(self, entity):\n",
    "        return self.entities[entity][0]\n",
    "\n",
    "    def markFound(self, entity, prevNode, relation):\n",
    "        self.entities[entity] = (True, prevNode, relation)\n",
    "\n",
    "    def reconstructPath(self, entity1, entity2): # after BFS\n",
    "        curNode,entity_list,path_list = entity2,[entity2],[] # from tail\n",
    "        while(curNode != entity1):       # status:(isFound,prevNode, relation)\n",
    "            path_list.append(self.entities[curNode][2]) # relation\n",
    "            curNode = self.entities[curNode][1]         # prevNode\n",
    "            entity_list.append(curNode)\n",
    "        return entity_list[::-1],path_list[::-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''.join([entity + \"[{},{},{}]\".format(status[0],status[1],status[2]) \\\n",
    "                        for entity, status in self.entities.iteritems()])\n",
    "\n",
    "def BFS(kb, entity1, entity2):\n",
    "    '''\n",
    "    input: kb=KB(),head,tail\n",
    "    output: (True, entity_list, path_list)\n",
    "    '''\n",
    "    path_finder = foundPaths(kb);path_finder.markFound(entity1, None, None)\n",
    "    q = Queue();q.put(entity1)\n",
    "    while(not q.empty()):\n",
    "        curNode = q.get()\n",
    "        for path in kb.getPathsFrom(curNode): # get connections\n",
    "            connectRelation,nextEntity = path.relation,path.connected_entity\n",
    "            if(not path_finder.isFound(nextEntity)): # put for continue search\n",
    "                q.put(nextEntity)\n",
    "                path_finder.markFound(nextEntity, curNode, connectRelation)\n",
    "            if(nextEntity == entity2): # arrive tail\n",
    "                entity_list, path_list = path_finder.reconstructPath(entity1, entity2)\n",
    "                return (True, entity_list, path_list)\n",
    "    return (False, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Env(object):\n",
    "    \"\"\"knowledge graph environment definition\"\"\"\n",
    "    def __init__(self, data_path, relation='concept:worksfor'):\n",
    "        self.entity2id_ = entity2id = dict([(line.split()[0],int(line.split()[1])) for line in \\\n",
    "                  codecs.open(data_path+'entity2id.txt','r',encoding='utf-8') if len(line.split()) == 2])\n",
    "        self.relation2id_ = relation2id = dict([(line.split()[0],int(line.split()[1])) for line in \\\n",
    "                    codecs.open(data_path+'relation2id.txt','r',encoding='utf-8') if len(line.split()) == 2])\n",
    "        self.relations = list(self.relation2id_.keys())\n",
    "        self.entity2vec = np.loadtxt(data_path + 'entity2vec.bern')\n",
    "        self.relation2vec = np.loadtxt(data_path + 'relation2vec.bern')\n",
    "\n",
    "        self.path = []\n",
    "        self.path_relations = []\n",
    "\n",
    "        # kb_env_rl filter:rel\n",
    "        self.kb = [line.rsplit() for line in codecs.open(data_path+'kb_env_rl.txt','r',encoding='utf-8')\\\n",
    "        if len(line.split()) == 2 and line.split()[2] != relation and line.split()[2] != relation+'_inv']\n",
    "\n",
    "        self.die = 0 # record how many times does the agent choose an invalid path\n",
    "\n",
    "    def interact(self, state, action):\n",
    "        '''\n",
    "        This function process the interact from the agent\n",
    "        state: is [current_position, target_position] \n",
    "        action: an integer\n",
    "        return: (reward, [new_postion, target_position], done)\n",
    "        '''\n",
    "        done = 0 # Whether the episode has finished\n",
    "        curr_pos,target_pos = state[:-1]\n",
    "        chosed_relation = self.relations[action]\n",
    "        choices = []\n",
    "        for triple in self.kb:\n",
    "            if curr_pos == self.entity2id_[triple[0]] \\\n",
    "                and triple[2] == chosed_relation \\\n",
    "                and triple[1] in self.entity2id_:\n",
    "                choices.append(self.entity2id_[triple[1]])\n",
    "        if len(choices) == 0:\n",
    "            reward = -1\n",
    "            self.die += 1\n",
    "            next_state = state # stay in the initial state\n",
    "            next_state[-1] = self.die\n",
    "            return (reward, next_state, done)\n",
    "        else: # find a valid step\n",
    "            next_pos = random.choice(choices)\n",
    "            self.path.append(chosed_relation + ' -> ' + next_pos)\n",
    "            self.path_relations.append(chosed_relation)\n",
    "            print('Find a valid step:',path,'Action index:',action)\n",
    "            self.die = 0\n",
    "            reward = 0\n",
    "            next_state = [next_pos, target_pos, self.die]\n",
    "\n",
    "            if next_pos == target_pos:\n",
    "                print('Find a path:',self.path)\n",
    "                done = 1\n",
    "                reward = 0\n",
    "                next_state = None\n",
    "            return (reward, next_state, done)\n",
    "\n",
    "    def idx_state(self, idx_list):\n",
    "        if idx_list != None:\n",
    "            curr = self.entity2vec[idx_list[0],:]\n",
    "            targ = self.entity2vec[idx_list[1],:]\n",
    "            return np.expand_dims(np.concatenate((curr, targ - curr)),axis=0)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_valid_actions(self, entityID): # valid action space <= action space\n",
    "        actions = set()\n",
    "        for triple in self.kb:\n",
    "            e1_idx = self.entity2id_[triple[0]]\n",
    "            if e1_idx == entityID:\n",
    "                actions.add(self.relation2id_[triple[2]])\n",
    "        return np.array(list(actions))\n",
    "\n",
    "    def path_embedding(self, path):\n",
    "        embeddings = [self.relation2vec[self.relation2id_[relation],:] for relation in path]\n",
    "        embeddings = np.reshape(embeddings, (-1,embedding_dim))\n",
    "        path_encoding = np.sum(embeddings, axis=0)\n",
    "        return np.reshape(path_encoding,(-1, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = Env(data_path, relation.replace('_',':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "state_dim = 200\n",
    "action_space = 400\n",
    "eps_start = 1\n",
    "eps_end = 0.1\n",
    "epe_decay = 1000\n",
    "replay_memory_size = 10000\n",
    "batch_size = 128\n",
    "embedding_dim = 100\n",
    "gamma = 0.99\n",
    "target_update_freq = 1000\n",
    "max_steps = 50\n",
    "max_steps_test = 50\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "def l2_distance(e1, e2):\n",
    "    return np.sqrt(np.sum(np.square(e1 - e2)))\n",
    "\n",
    "def compare(v1, v2):\n",
    "    return sum(v1 == v2)\n",
    "\n",
    "def prob_norm(probs):\n",
    "    return probs/sum(probs)\n",
    "\n",
    "def teacher(e1, e2, num_paths, env, path = None):\n",
    "    kb = KB()\n",
    "    [kb.addRelation(line.rsplit()[0],line.rsplit()[1],line.rsplit()[2]) \\\n",
    "     for line in codecs.open(path,'r',encoding='utf-8')]\n",
    "    # Bi-BFS path collect\n",
    "    intermediates = kb.pickRandomIntermediatesBetween(e1, e2, num_paths)\n",
    "    print('intermediates:',intermediates)      \n",
    "    entity_lists = [];path_lists = []\n",
    "    for i in range(num_paths):\n",
    "        suc1, entity_list1, path_list1 = BFS(kb, e1, intermediates[i]);print('{}:BFS left done'.format(i))\n",
    "        suc2, entity_list2, path_list2 = BFS(kb, intermediates[i], e2);print('{}:BFS right done'.format(i))\n",
    "        if suc1 and suc2:\n",
    "            entity_lists.append(entity_list1 + entity_list2[1:])\n",
    "            path_lists.append(path_list1 + path_list2)\n",
    "    print('BFS found paths:', len(path_lists))\n",
    "    # clean the path \n",
    "    # duplicate\n",
    "    # drop [min:max]\n",
    "    print('path clean')\n",
    "    entity_lists_new = []\n",
    "    path_lists_new = []\n",
    "    for entities, relations in zip(entity_lists, path_lists):\n",
    "        path = [entities[int(i/2)] if i%2 == 0 else relations[int(i/2)]\\\n",
    "                    for i in range(len(entities)+len(relations))]\n",
    "        entity_stats = Counter(entities).items()\n",
    "        duplicate_ents = [item for item in entity_stats if item[1]!=1]\n",
    "        duplicate_ents.sort(key = lambda x:x[1], reverse=True)\n",
    "        for item in duplicate_ents:\n",
    "            ent = item[0]\n",
    "            ent_idx = [i for i,x in enumerate(path) if x == ent]\n",
    "            if len(ent_idx)!=0:\n",
    "                min_idx = min(ent_idx)\n",
    "                max_idx = max(ent_idx)\n",
    "                if min_idx!=max_idx:\n",
    "                    path = path[:min_idx] + path[max_idx:]\n",
    "        entities_new = []\n",
    "        relations_new = []\n",
    "        for idx, item in enumerate(path):\n",
    "            if idx%2 == 0:\n",
    "                entities_new.append(item)\n",
    "            else:\n",
    "                relations_new.append(item)\n",
    "        entity_lists_new.append(entities_new);path_lists_new.append(relations_new)\n",
    "    print('len(entities):',len(entity_lists_new),'len(paths):',len(path_lists_new))\n",
    "    # episodes\n",
    "    print('collect episodes')\n",
    "    good_episodes = []\n",
    "    targetID = env.entity2id_[e2]\n",
    "    for path in zip(entity_lists_new,path_lists_new):\n",
    "        good_episode = []\n",
    "        for i in range(len(path[0]) -1):\n",
    "            currID = env.entity2id_[path[0][i]];nextID = env.entity2id_[path[0][i+1]]\n",
    "            state_curr = [currID, targetID, 0];state_next = [nextID, targetID, 0]\n",
    "            actionID = env.relation2id_[path[1][i]]\n",
    "            good_episode.append(Transition(state = env.idx_state(state_curr),\\\n",
    "                                           action = actionID, \\\n",
    "                                           next_state = env.idx_state(state_next), \\\n",
    "                                           reward = 1)) # each time step reward==1\n",
    "        good_episodes.append(good_episode)\n",
    "    return good_episodes\n",
    "\n",
    "def path_clean(path):\n",
    "    rel_ents = path.split(' -> ')\n",
    "    relations = []\n",
    "    entities = []\n",
    "    for idx, item in enumerate(rel_ents):\n",
    "        if idx%2 == 0:\n",
    "            relations.append(item)\n",
    "        else:\n",
    "            entities.append(item)\n",
    "    entity_stats = Counter(entities).items()\n",
    "    duplicate_ents = [item for item in entity_stats if item[1]!=1]\n",
    "    duplicate_ents.sort(key = lambda x:x[1], reverse=True)\n",
    "    for item in duplicate_ents:\n",
    "        ent = item[0]\n",
    "        ent_idx = [i for i, x in enumerate(rel_ents) if x == ent]\n",
    "        if len(ent_idx)!=0:\n",
    "            min_idx = min(ent_idx)\n",
    "            max_idx = max(ent_idx)\n",
    "            if min_idx!=max_idx:\n",
    "                rel_ents = rel_ents[:min_idx] + rel_ents[max_idx:]\n",
    "    return ' -> '.join(rel_ents)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path_clean('/common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/01d34b -> /common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/0lfyx -> /common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/01y67v -> /common/topic/webpage./common/webpage/category -> /m/08mbj5d -> /common/topic/webpage./common/webpage/category_inv -> /m/028qyn -> /people/person/nationality -> /m/09c7w0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### networks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_nn(state, state_dim, action_dim, initializer):\n",
    "    \"\"\"\n",
    "    策略网络(P(a_t|s_t;theta))\n",
    "    state_dim -relu-> 512 -relu-> 1024 -softmax-> action_dim\n",
    "    state -> action_prob [action_dim]\n",
    "    action_dim == 关系数量\n",
    "    \"\"\"\n",
    "    w1 = tf.get_variable('W1', [state_dim, 512], initializer = initializer, regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    b1 = tf.get_variable('b1', [512], initializer = tf.constant_initializer(0.0))\n",
    "    h1 = tf.nn.relu(tf.matmul(state, w1) + b1)\n",
    "    w2 = tf.get_variable('w2', [512, 1024], initializer = initializer, regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    b2 = tf.get_variable('b2', [1024], initializer = tf.constant_initializer(0.0))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    w3 = tf.get_variable('w3', [1024, action_dim], initializer = initializer, regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    b3 = tf.get_variable('b3', [action_dim], initializer = tf.constant_initializer(0.0))\n",
    "    action_prob = tf.nn.softmax(tf.matmul(h2,w3) + b3)\n",
    "    return action_prob\n",
    "\n",
    "def value_nn(state, state_dim, initializer):\n",
    "    \"\"\"\n",
    "    state_dim -relu-> 64 -> 1\n",
    "    state -> value_estimated\n",
    "    \"\"\"\n",
    "    w1 = tf.get_variable('w1', [state_dim, 64], initializer = initializer)\n",
    "    b1 = tf.get_variable('b1', [64], initializer = tf.constant_initializer(0.0))\n",
    "    h1 = tf.nn.relu(tf.matmul(state,w1) + b1)\n",
    "    w2 = tf.get_variable('w2', [64,1], initializer = initializer)\n",
    "    b2 = tf.get_variable('b2', [1], initializer = tf.constant_initializer(0.0))\n",
    "    value_estimated = tf.matmul(h1, w2) + b2\n",
    "    return tf.squeeze(value_estimated)\n",
    "\n",
    "def q_network(state, state_dim, action_space, initializer):\n",
    "    \"\"\"\n",
    "    state_dim -relu-> 128 -relu-> 64 -> action_space\n",
    "    state -> [w1,b1,w2,b2,w3,b3,action_values]\n",
    "    \"\"\"\n",
    "    w1 = tf.get_variable('w1', [state_dim, 128], initializer=initializer)\n",
    "    b1 = tf.get_variable('b1', [128], initializer = tf.constant_initializer(0))\n",
    "    h1 = tf.nn.relu(tf.matmul(state, w1) + b1)\n",
    "    w2 = tf.get_variable('w2', [128, 64], initializer = initializer)\n",
    "    b2 = tf.get_variable('b2', [64], initializer = tf.constant_initializer(0))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    w3 = tf.get_variable('w3', [64, action_space], initializer = initializer)\n",
    "    b3 = tf.get_variable('b3', [action_space], initializer = tf.constant_initializer(0))\n",
    "    action_values = tf.matmul(h2, w3) + b3\n",
    "    return [w1,b1,w2,b2,w3,b3,action_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pairs = [line for line in codecs.open(task_path+'train_pos','r',encoding='utf-8')]\n",
    "test_pairs = train_pairs  #= [line for line in codecs.open(task_path+'sort_test.pairs','r',encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sl_policy.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SupervisedPolicy(object):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer()\n",
    "        with tf.variable_scope('supervised_policy'):\n",
    "            self.state = tf.placeholder(tf.float32, [None, state_dim], name = 'state')\n",
    "            self.action = tf.placeholder(tf.int32, [None], name = 'action')\n",
    "            self.action_prob = policy_nn(self.state, state_dim, action_space, self.initializer)\n",
    "            action_mask = tf.cast(tf.one_hot(self.action, depth = action_space), tf.bool)\n",
    "            self.picked_action_prob = tf.boolean_mask(self.action_prob, action_mask)\n",
    "\n",
    "            self.loss = tf.reduce_sum(-tf.log(self.picked_action_prob)) + \\\n",
    "                                    sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope = 'supervised_policy'))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "    def predict(self, state, sess = None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        return sess.run(self.action_prob, {self.state: state})\n",
    "\n",
    "    def update(self, state, action, sess = None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        _, loss = sess.run([self.train_op, self.loss], {self.state: state, self.action: action})\n",
    "        return loss\n",
    "\n",
    "def sl_train(episodes=500):\n",
    "    tf.reset_default_graph()\n",
    "    policy_nn = SupervisedPolicy()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for episode in range(len(train_pairs) if len(train_pairs)<episodes else episodes):\n",
    "            #import pdb;pdb.set_trace()\n",
    "            print(\"Episode %d\" % episode);print('Training Sample:', train_pairs[episode%episodes][:-1])\n",
    "            sample = train_pairs[episode%episodes].split()\n",
    "            try:\n",
    "                good_episodes = teacher(sample[0], sample[1], 5, env, task_path+'graph.txt') # good_episodes from teacher\n",
    "            except Exception as e:\n",
    "                print('Cannot find a path');continue\n",
    "\n",
    "            for item in good_episodes: # one episode one supervised batch*<state,action> to update theta\n",
    "                state_batch,action_batch = [],[]\n",
    "                for t, transition in enumerate(item):\n",
    "                    state_batch.append(transition.state)\n",
    "                    action_batch.append(transition.action)\n",
    "                state_batch = np.squeeze(state_batch)\n",
    "                state_batch = np.reshape(state_batch, [-1, state_dim])\n",
    "                policy_nn.update(state_batch, action_batch)\n",
    "        saver.save(sess, 'models/policy_supervised_' + relation)\n",
    "        print('Model saved')\n",
    "\n",
    "\n",
    "def sl_test(episodes=300):\n",
    "    tf.reset_default_graph()\n",
    "    policy_nn = SupervisedPolicy()\n",
    "    print('len(test_pairs):',len(test_pairs),'test_episodes:',episodes)\n",
    "    success = 0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, 'models/policy_supervised_'+ relation);print('Model reloaded')\n",
    "        for episode in range(episodes):\n",
    "            print('Test sample %d: %s' % (episode,test_pairs[episode][:-1]))\n",
    "            sample = test_pairs[episode].split()\n",
    "            state_idx = [env.entity2id_[sample[0]], env.entity2id_[sample[1]], 0]\n",
    "            for t in count():\n",
    "                state_vec = env.idx_state(state_idx)\n",
    "                action_probs = policy_nn.predict(state_vec)\n",
    "                action_chosen = np.random.choice(np.arange(action_space), p = np.squeeze(action_probs))\n",
    "                reward, new_state, done = env.interact(state_idx, action_chosen)\n",
    "                if done or t == max_steps_test:\n",
    "                    if done:\n",
    "                        print('Success')\n",
    "                        success += 1\n",
    "                    print('Episode ends\\n')\n",
    "                    break\n",
    "                state_idx = new_state\n",
    "\n",
    "    print('Success persentage:', success/episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sl_train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sl_test(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### policy_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PolicyNetwork(object):\n",
    "    def __init__(self, scope = 'policy_network', learning_rate = 0.001):\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer()\n",
    "        with tf.variable_scope(scope):\n",
    "            self.state = tf.placeholder(tf.float32, [None, state_dim], name = 'state')\n",
    "            self.action = tf.placeholder(tf.int32, [None], name = 'action')\n",
    "            # +target\n",
    "            self.target = tf.placeholder(tf.float32, name = 'target')\n",
    "            self.action_prob = policy_nn(self.state, state_dim, action_space, self.initializer)\n",
    "\n",
    "            action_mask = tf.cast(tf.one_hot(self.action, depth = action_space), tf.bool)\n",
    "            self.picked_action_prob = tf.boolean_mask(self.action_prob, action_mask)\n",
    "            # +target\n",
    "            self.loss = tf.reduce_sum(-tf.log(self.picked_action_prob)*self.target) + \\\n",
    "                                    sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=scope))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "\n",
    "    def predict(self, state, sess = None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        return sess.run(self.action_prob, {self.state:state})\n",
    "\n",
    "    def update(self, state, target, action, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        # +target\n",
    "        feed_dict = { self.state: state, self.target: target, self.action: action  }\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def REINFORCE(train_pairs, policy_nn, num_episodes):\n",
    "    success = 0\n",
    "    path_found = []\n",
    "    for i_episode in range(num_episodes):\n",
    "        start = time.time()\n",
    "        print('Episode %d' % i_episode);print('Training sample: ', train_pairs[i_episode][:-1])\n",
    "        sample = train_pairs[i_episode].split()\n",
    "        state_idx = [env.entity2id_[sample[0]], env.entity2id_[sample[1]], 0]\n",
    "        episode,state_batch_negative,action_batch_negative = [],[],[]\n",
    "        for t in count():\n",
    "            state_vec = env.idx_state(state_idx)\n",
    "            action_probs = policy_nn.predict(state_vec)\n",
    "            action_chosen = np.random.choice(np.arange(action_space), p = np.squeeze(action_probs))\n",
    "            reward, new_state_idx, done = env.interact(state_idx, action_chosen)\n",
    "            # the action fails for this step\n",
    "            if reward == -1: \n",
    "                state_batch_negative.append(state_vec)\n",
    "                action_batch_negative.append(action_chosen)\n",
    "            new_state_vec = env.idx_state(new_state_idx)\n",
    "            episode.append(Transition(state = state_vec,\\\n",
    "                                      action = action_chosen,\\\n",
    "                                      next_state = new_state_vec,\\\n",
    "                                      reward = reward))\n",
    "            if done or t == max_steps:break\n",
    "            state_idx = new_state_idx\n",
    "        # Discourage the agent when it choose an invalid step\n",
    "        if len(state_batch_negative) != 0:\n",
    "            print('Penalty to invalid steps:',len(state_batch_negative))\n",
    "            policy_nn.update(np.reshape(state_batch_negative, (-1, state_dim)), -0.05, action_batch_negative)\n",
    "\n",
    "        # If the agent success, do one optimization\n",
    "        def update_episode(policy_nn,episode,total_reward):      \n",
    "            state_batch = []\n",
    "            action_batch = []\n",
    "            for t, transition in enumerate(episode):\n",
    "                if transition.reward == 0:\n",
    "                    state_batch.append(transition.state)\n",
    "                    action_batch.append(transition.action)\n",
    "            policy_nn.update(np.reshape(state_batch,(-1,state_dim)), total_reward, action_batch)\n",
    "            \n",
    "        if done == 1:\n",
    "            print('Success')\n",
    "            path_found.append(path_clean(' -> '.join(env.path)))\n",
    "            success += 1\n",
    "            length_reward,global_reward = 1/len(env.path),1\n",
    "            total_reward = 0.1*global_reward + 0.9*length_reward\n",
    "            update_episode(policy_nn,episode,total_reward)\n",
    "        else:\n",
    "            global_reward = -0.05\n",
    "            update_episode(policy_nn,episode,global_reward)\n",
    "            print('Failed, Do one teacher guideline')\n",
    "            try:\n",
    "                good_episodes = teacher(sample[0], sample[1], 1, env, task_path+'graph.txt')\n",
    "                [update_episode(policy_nn,episode,1) for episode in good_episodes]\n",
    "            except Exception as e:\n",
    "                print('Teacher guideline failed')\n",
    "        print('Episode time: ',time.time() - start)\n",
    "    print('Success percentage:',success/num_episodes)\n",
    "    # reset env path\n",
    "    env.path,env.path_relations = [],[]\n",
    "    # store path stats\n",
    "    path_found_relation = [' -> '.join([rel for ix,rel in enumerate(path.split(' -> ')) if ix%2 == 0]) \\\n",
    "                                                                                 for path in path_found]\n",
    "    relation_path_stats = sorted(Counter(path_found_relation).items(),key = lambda x:x[1],reverse=True)\n",
    "    with codecs.open('./tasks/'+relation+'/path_stats.txt','w',encoding='utf-8') as f:\n",
    "        [f.write(item[0]+'\\t'+str(item[1])+'\\n') for item in relation_path_stats]\n",
    "        print('Path stats saved')\n",
    "\n",
    "def rl_retrain(episodes=300):\n",
    "    print('Start retraining');tf.reset_default_graph()\n",
    "    policy_network = PolicyNetwork(scope = 'supervised_policy') # restore form parameters of supervised_policy\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, 'models/policy_supervised_' + relation);print(\"sl_policy restored\")\n",
    "        REINFORCE(train_pairs, policy_network, len(train_pairs) if len(train_pairs)<episodes else episodes)\n",
    "        saver.save(sess, 'models/policy_retrained_' + relation)\n",
    "    print('Retrained model saved')\n",
    "\n",
    "def rl_test(episodes=500):\n",
    "    tf.reset_default_graph()\n",
    "    policy_network = PolicyNetwork(scope = 'supervised_policy') # restore form parameters of supervised_policy\n",
    "    success = 0\n",
    "    saver = tf.train.Saver()\n",
    "    path_found = []\n",
    "    path_set = set()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, 'models/policy_retrained_' + relation);print('Model reloaded')\n",
    "        for episode in range(len(test_pairs) if len(test_pairs)<episodes else episodes):\n",
    "            print('Test sample %d: %s' % (episode,test_pairs[episode][:-1]))\n",
    "            sample = test_pairs[episode].split()\n",
    "            state_idx = [env.entity2id_[sample[0]], env.entity2id_[sample[1]], 0]\n",
    "            transitions = []\n",
    "            for t in count():\n",
    "                state_vec = env.idx_state(state_idx)\n",
    "                action_probs = np.squeeze(policy_network.predict(state_vec))\n",
    "                action_chosen = np.random.choice(np.arange(action_space), p = action_probs)\n",
    "                reward, new_state, done = env.interact(state_idx, action_chosen)\n",
    "                new_state_vec = env.idx_state(new_state)\n",
    "                transitions.append(Transition(state = state_vec, action = action_chosen, next_state = new_state_vec, reward = reward))\n",
    "                if done or t == max_steps_test:\n",
    "                    if done:\n",
    "                        success += 1;print(\"Success\")\n",
    "                        path_found.append(path_clean(' -> '.join(env.path)))\n",
    "                    else:\n",
    "                        print('Episode ends due to step limit')\n",
    "                    break\n",
    "                state_idx = new_state\n",
    "            if done:\n",
    "                if len(path_set) != 0:\n",
    "                    path_found_embedding = [env.path_embedding(path.split(' -> ')) for path in path_set]\n",
    "                    curr_path_embedding = env.path_embedding(env.path_relations)\n",
    "                    path_found_embedding = np.reshape(path_found_embedding, (-1,embedding_dim))\n",
    "                    cos_sim = cosine_similarity(path_found_embedding, curr_path_embedding)\n",
    "                    diverse_reward = -np.mean(cos_sim)\n",
    "                    print('diverse_reward', diverse_reward)\n",
    "                    #total_reward = 0.1*global_reward + 0.8*length_reward + 0.1*diverse_reward \n",
    "                    state_batch = []\n",
    "                    action_batch = []\n",
    "                    for t, transition in enumerate(transitions):\n",
    "                        if transition.reward == 0:\n",
    "                            state_batch.append(transition.state)\n",
    "                            action_batch.append(transition.action)\n",
    "                    policy_network.update(np.reshape(state_batch,(-1,state_dim)), 0.1*diverse_reward, action_batch)\n",
    "                path_set.add(' -> '.join(env.path_relations))\n",
    "    print('Success persentage:', success/episodes)\n",
    "    # env path reset\n",
    "    env.path,env.path_relations = [],[]\n",
    "    # store path to use \n",
    "    path_found_relation = [' -> '.join([rel for ix,rel in enumerate(path.split(' -> ')) if ix%2 == 0]) \\\n",
    "                                                                                 for path in path_found]\n",
    "    relation_path_stats = sorted(Counter(path_found_relation).items(), key = lambda x:x[1], reverse=True)\n",
    "    ranking_path = sorted([(path_stat[0],len(path_stat[0].split(' -> '))) \\\n",
    "                           for path_stat in relation_path_stats],\\\n",
    "                          key = lambda x:x[1])\n",
    "    with codecs.open('./tasks/'+relation+'/path_to_use.txt','w',encoding='utf-8') as f:\n",
    "        [f.write(item[0]+'\\n') for item in ranking_path]\n",
    "        print('path to use saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rl_retrain(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rl_test(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fact_prediction_eval.py\n",
    "```\n",
    "def bfs_two\n",
    "def get_features\n",
    "ap:\n",
    "TransE\n",
    "TransR\n",
    "RL\n",
    "TransH\n",
    "TransD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict\n",
    "entity2id = dict([(line.split()[0],int(line.split()[1])) for line in \\\n",
    "                  codecs.open(task_path+'entity2id.txt','r',encoding='utf-8') if len(line.split()) == 2])\n",
    "relation2id = dict([(line.split()[0],int(line.split()[1])) for line in \\\n",
    "                    codecs.open(task_path+'relation2id.txt','r',encoding='utf-8') if len(line.split()) == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75492"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relation2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rel\n",
    "rel = relation.replace(\"_\", \":\") # concept_athletehomestadium -> concept:athletehomestadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TransE\n",
    "ent_vec_E = np.loadtxt(task_path+'entity2vec.unif')\n",
    "rel_vec_E = np.loadtxt(task_path+'relation2vec.unif')\n",
    "relation_vec_E = rel_vec_E[relation2id[rel],:] # TransE relation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation2id[rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75492, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_vec_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_vec_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_vec_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TransR\n",
    "ent_vec_R = np.loadtxt(task_path+'entity2vec.bern')\n",
    "rel_vec_R = np.loadtxt(task_path+'relation2vec.bern')\n",
    "M_R = np.loadtxt(task_path+'A.bern') #投影矩阵\n",
    "M_R = M_R.reshape([-1,50,50])\n",
    "relation_vec_R = rel_vec_R[relation2id[rel],:]#关系向量TransR\n",
    "M_R_vec = M_R[relation2id[rel],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 50)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(task_path+'A.bern').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 50, 50)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_R_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TransH\n",
    "ent_vec_H = np.loadtxt(task_path+'entity2vec.vec')\n",
    "rel_vec_H = np.loadtxt(task_path+'relation2vec.vec')\n",
    "M_H = np.loadtxt(task_path+'A.vec')\n",
    "M_H = M_H.reshape([rel_vec_H.shape[0],-1])\n",
    "relation_vec_H = d_r = np.expand_dims(rel_vec_H[relation2id[rel],:],1)\n",
    "w_r = np.expand_dims(M_H[relation2id[rel],:],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 50)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TransD\n",
    "ent_vec_D = np.loadtxt(task_path+'entity2vec.vec_D')\n",
    "rel_vec_D = np.loadtxt(task_path+'relation2vec.vec_D')\n",
    "M_D = np.loadtxt(task_path+'A.vec_D')\n",
    "ent_num = ent_vec_D.shape[0]\n",
    "rel_num = rel_vec_D.shape[0]\n",
    "rel_tran = M_D[0:rel_num,:]\n",
    "ent_tran = M_D[rel_num:,:]\n",
    "dim_D = ent_vec_D.shape[1]\n",
    "\n",
    "r = np.expand_dims(rel_vec_D[relation2id[rel],:], 1)\n",
    "r_p = np.expand_dims(rel_tran[relation2id[rel],:], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(task_path,relation2id):\n",
    "    stats = dict([(line.split('\\t')[0],int(line.split('\\t')[1])) for line in \\\n",
    "                  codecs.open(task_path+'path_stats.txt','r',encoding='utf-8') if len(line.split()) == 2])\n",
    "    max_freq = max(stats.values()) #路径最大次数\n",
    "    useful_paths = [] # ids path list\n",
    "    named_paths = [] # rel_names path list\n",
    "    paths = [line.rstrip() for line in codecs.open(task_path+'path_to_use.txt','r',encoding='utf-8')]\n",
    "    for path in paths:\n",
    "        # filter: not in stats and count less\n",
    "        if path not in stats:\n",
    "            continue\n",
    "        elif max_freq > 1 and stats[path] < 2: \n",
    "            continue\n",
    "        # filter: len(path)<=0\n",
    "        if len(path.split(' -> ')) <= 10:\n",
    "            pathIndex = []\n",
    "            pathName = []\n",
    "            relations = path.split(' -> ')\n",
    "            for rel in relations:\n",
    "                pathName.append(rel)\n",
    "                rel_id = relation2id[rel]\n",
    "                pathIndex.append(rel_id)\n",
    "            useful_paths.append(pathIndex)\n",
    "            named_paths.append(pathName)\n",
    "    return useful_paths, named_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features\n",
    "id_path,name_path = get_features(task_path,relation2id)\n",
    "path_weights = np.array([1.0/len(path) for path in name_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[130], [254], [15], [193], [252], [35]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['concept:personleadsorganization'],\n",
       " ['concept:organizationhiredperson_inv'],\n",
       " ['concept:agentcollaborateswithagent_inv'],\n",
       " ['concept:journalistwritesforpublication'],\n",
       " ['concept:mutualproxyfor_inv'],\n",
       " ['concept:organizationterminatedperson_inv']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kb\n",
    "kb = KB()       #知识库\n",
    "kb_inv = KB()   #逆向\n",
    "for line in codecs.open(task_path+'graph.txt'):\n",
    "    e1,rel,e2 = line.split()\n",
    "    kb.addRelation(e1,rel,e2)     # entities{entity1：Path{.relation.connected_entity}(relation, entity2)}\n",
    "    kb_inv.addRelation(e2,rel,e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75227"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kb.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75227"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kb_inv.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\tconcept:proxyfor\tconcept_book_new,\n",
       " \tconcept:locationlocatedwithinlocation_inv\tconcept_lake_new,\n",
       " \tconcept:atlocation_inv\tconcept_beverage_new]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.entities['concept_politicsblog_perspective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\tconcept:proxyfor_inv\tconcept_book_new,\n",
       " \tconcept:locationlocatedwithinlocation\tconcept_lake_new,\n",
       " \tconcept:atlocation\tconcept_beverage_new]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_inv.entities['concept_politicsblog_perspective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read_samples\n",
    "# thing$concept_politician_sam_sullivan,thing$concept_city_whistler:-\n",
    "def read_samples(task_path,pairs_file='train.pairs'):\n",
    "    pairs,labels = [],[]\n",
    "    for line in codecs.open(task_path+pairs_file,'r',encoding='utf-8'):\n",
    "        e1 = line.split(',')[0].replace('thing$','')\n",
    "        e2 = line.split(',')[1].split(':')[0].replace('thing$','')\n",
    "        if (e1 not in kb.entities) or (e2 not in kb.entities):\n",
    "            continue\n",
    "        pairs.append((e1,e2))\n",
    "        labels.append(1 if line[-2] == '+' else 0)\n",
    "    return pairs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs,test_labels = read_samples(task_path,'sort_test.pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('concept_actor_peter_king', 'concept_blog_sports_illustrated'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_company_post'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_company_sun'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_company_sun_microsystems001'),\n",
       " ('concept_celebrity_sam_phillips', 'concept_newspaper_journal')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2698"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set().add('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bi_path_search(e1,e2,path,kb,kb_inv):\n",
    "    '''\n",
    "    :the bidirectional search for reasoning\n",
    "    e1,r1,ex,r2,e2\n",
    "    path:start-><-end:r1,r2\n",
    "    kb:->:e1,r1,ex|ex,r2,e2\n",
    "    kb_inv:<-:ex,r1,e1|e2,r2,ex\n",
    "    '''\n",
    "    start,end = 0,len(path)\n",
    "    left,right = set(),set()\n",
    "    left.add(e1)\n",
    "    right.add(e2)\n",
    "    left_path,right_path = [],[]\n",
    "    while(start < end):\n",
    "        left_step = path[start]\n",
    "        left_next = set()\n",
    "        right_step = path[end-1]\n",
    "        right_next = set()\n",
    "\n",
    "        if len(left) < len(right):\n",
    "            left_path.append(left_step)\n",
    "            start += 1\n",
    "            for entity in left: # BFS loop\n",
    "                try:\n",
    "                    for path_ in kb.getPathsFrom(entity):\n",
    "                        if path_.relation == left_step:\n",
    "                            left_next.add(path_.connected_entity)\n",
    "                except Exception as e:\n",
    "                    #print('len(left):',len(left),left,'not such entity')\n",
    "                    return False\n",
    "            left = left_next\n",
    "\n",
    "        else: # start->end;kb->kb_inv\n",
    "            right_path.append(right_step)\n",
    "            end -= 1\n",
    "            for entity in right:\n",
    "                try:\n",
    "                    for path_ in kb_inv.getPathsFrom(entity):\n",
    "                        if path_.relation == right_step:\n",
    "                            right_next.add(path_.connected_entity)\n",
    "                except Exception as e:\n",
    "                    #print('len(right):',len(right),right,'not such entity')\n",
    "                    return False\n",
    "            right = right_next\n",
    "    #if len(right & left) != 0:\n",
    "     #   print(left,right)\n",
    "    return True if len(right & left) != 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aps\n",
    "def entity2vec(ent_vec,entity,M_vec=None,w_r=None):\n",
    "    if isinstance(w_r,np.ndarray):\n",
    "        ent = np.expand_dims(ent_vec[entity2id[entity],:],1)\n",
    "        ent_ = ent - np.matmul(w_r.transpose(), ent)*w_r\n",
    "        return ent_\n",
    "    if isinstance(M_vec,np.ndarray):\n",
    "        return np.matmul(ent_vec[entity2id[entity],:], M_vec)\n",
    "    return ent_vec[entity2id[entity],:]\n",
    "\n",
    "def l2_score(h,r,t):\n",
    "    return -np.sum(np.square(h + r - t))\n",
    "\n",
    "scores_E = [l2_score(entity2vec(ent_vec_E,pair[0]),relation_vec_E,entity2vec(ent_vec_E,pair[1])) for pair in test_pairs]\n",
    "scores_R = [l2_score(entity2vec(ent_vec_R,pair[0],M_vec=M_R_vec),relation_vec_R,entity2vec(ent_vec_R,pair[1],M_vec=M_R_vec)) for pair in test_pairs]\n",
    "scores_rl = [sum(path_weights*[int(bi_path_search(pair[0], pair[1], path, kb, kb_inv)) for path in name_path]) for pair in test_pairs]\n",
    "scores_H = [l2_score(entity2vec(ent_vec_H,pair[0],w_r=w_r),relation_vec_H,entity2vec(ent_vec_H,pair[1],w_r=w_r)) for pair in test_pairs]\n",
    "\n",
    "def score_D(ent_vec_D,ent_tran,pair):\n",
    "    h = np.expand_dims(ent_vec_D[entity2id[pair[0]],:], 1)\n",
    "    h_p = np.expand_dims(ent_tran[entity2id[pair[0]],:], 1)\n",
    "    t = np.expand_dims(ent_vec_D[entity2id[pair[1]],:], 1)\n",
    "    t_p = np.expand_dims(ent_tran[entity2id[pair[1]],:], 1)\n",
    "    M_rh = np.matmul(r_p, h_p.transpose()) + np.identity(dim)\n",
    "    M_rt = np.matmul(r_p, t_p.transpose()) + np.identity(dim)\n",
    "    score = - np.sum(np.square(M_rh.dot(h) + r - M_rt.dot(t)))\n",
    "    return score\n",
    "    \n",
    "scores_D =[score_D(ent_vec_D,ent_tran,pair) for pair in test_pairs] \n",
    "\n",
    "def ap(scores,test_labels):\n",
    "    # evaluate rank quality\n",
    "    # 1 1 1 0 0 0 better than 0 0 0 1 1 1\n",
    "    rank_stats = sorted(zip(scores, test_labels),key = lambda x:x[0], reverse=True)\n",
    "    correct = 0\n",
    "    ranks = []\n",
    "    for idx, item in enumerate(rank_stats):\n",
    "        if item[1] == 1:\n",
    "            correct += 1\n",
    "            ranks.append(correct/(1.0+idx)) # append precision\n",
    "    return np.mean(ranks) if len(ranks) != 0 else 0\n",
    "\n",
    "models = {\n",
    "    'E':ap(scores_E, test_labels),\n",
    "    'R':ap(scores_R, test_labels),\n",
    "    'rl':ap(scores_rl, test_labels),\n",
    "    'H':ap(scores_H, test_labels),\n",
    "    'D':ap(scores_D, test_labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 0.23670935347580135,\n",
       " 'E': 0.23067132455999617,\n",
       " 'H': 0.2476364956250818,\n",
       " 'R': 0.28690542314091916,\n",
       " 'rl': 0.48808056673088396}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mAP = np.sum((recalls[indices] - recalls[indices - 1]) *\n",
    "                 precisions[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### link_prediction_eval.sh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "relation=$1\n",
    "\n",
    "python evaluate.py $relation \n",
    "python transR_eval.py $relation\n",
    "python transE_eval.py $relation\n",
    "python transX_eval.py $relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(kb, kb_inv, name_path):\n",
    "    train_pairs,train_labels = read_samples(task_path,'train.pairs')\n",
    "    training_features = [[int(bi_path_search(pair[0], pair[1], path, kb, kb_inv)) for path in name_path] for pair in train_pairs]\n",
    "    model = Sequential()\n",
    "    input_dim = len(name_path)\n",
    "    model.add(Dense(1, activation='sigmoid' ,input_dim=input_dim))\n",
    "    model.compile(optimizer = 'rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(training_features, train_labels, nb_epoch=300, batch_size=128)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = train(kb, kb_inv, name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.5511950207386302\n"
     ]
    }
   ],
   "source": [
    "y_scores = [model.predict(np.reshape([int(bi_path_search(pair[0], pair[1], path, kb, kb_inv)) for path in name_path],[1,-1])) for pair in test_pairs]\n",
    "ap_link = ap(y_scores,test_labels)\n",
    "mAP = np.mean(ap_link)\n",
    "print('mAP:',mAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
